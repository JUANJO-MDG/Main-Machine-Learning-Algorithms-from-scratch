"""

# üìâ Implementaci√≥n Desde Cero de la Regresi√≥n Lineal

Este proyecto es una **implementaci√≥n completa y educativa de la Regresi√≥n Lineal** construida desde cero en Python. El objetivo principal es desmitificar este algoritmo fundamental de machine learning, permitiendo que comprendas su funcionamiento interno sin depender de librer√≠as de alto nivel para el n√∫cleo del c√°lculo. El notebook te gu√≠a paso a paso a trav√©s de la preparaci√≥n de los datos, el entrenamiento del modelo, la evaluaci√≥n de su rendimiento y la visualizaci√≥n de los resultados.

---

## üìå Visi√≥n General del Proyecto

El coraz√≥n de este proyecto reside en entender la **Regresi√≥n Lineal** desde sus fundamentos matem√°ticos hasta su aplicaci√≥n en c√≥digo. El enfoque es puramente did√°ctico y se centra en los siguientes componentes clave:

- **Preparaci√≥n de Datos**: Procesar y organizar los datos para que el modelo pueda utilizarlos de manera eficiente.
- **Implementaci√≥n del Modelo**: Escribir las funciones principales de la regresi√≥n lineal desde cero, incluyendo el c√°lculo del gradiente y la actualizaci√≥n de los par√°metros.
- **M√©tricas de Evaluaci√≥n**: Calcular m√©tricas de rendimiento como el **Error Cuadr√°tico Medio (MSE)** y el **Coeficiente de Determinaci√≥n (R¬≤)** para evaluar la precisi√≥n del modelo.
- **Visualizaci√≥n**: Graficar la l√≠nea de mejor ajuste y el comportamiento del error durante el entrenamiento para una comprensi√≥n visual del proceso.

---

## üõ†Ô∏è Metodolog√≠a y Componentes del Modelo

### 1. Fundamentos Matem√°ticos

El modelo opera bajo el principio de encontrar la l√≠nea que mejor se ajusta a los datos, minimizando la distancia vertical entre los puntos de datos y la l√≠nea.

- **Funci√≥n de Hip√≥tesis**: La predicci√≥n se basa en la f√≥rmula de una l√≠nea recta:
  \[
  y = mx + b
  \]
  donde `m` es la pendiente (o vector de pesos, **w**) y `b` es el intercepto (o sesgo, **b**).
- **Funci√≥n de P√©rdida (MSE)**: Se utiliza el **Error Cuadr√°tico Medio** para medir el error del modelo. La implementaci√≥n busca minimizar este valor para encontrar los par√°metros √≥ptimos (`m` y `b`).

### 3. Entrenamiento

El entrenamiento es un proceso iterativo de optimizaci√≥n a trav√©s del **descenso de gradiente**. En cada iteraci√≥n:

- Se calculan las predicciones del modelo.
- Se calcula la diferencia entre las predicciones y los valores reales.
- Se ajustan los par√°metros (`m` y `b`) en la direcci√≥n opuesta al gradiente de la funci√≥n de p√©rdida.
- El proceso se repite hasta alcanzar la convergencia.

### 4. Evaluaci√≥n del Rendimiento

Despu√©s del entrenamiento, se eval√∫a el modelo utilizando:

- **Error Cuadr√°tico Medio (MSE)**: Mide el promedio de los errores al cuadrado entre las predicciones y los valores reales.
- **Coeficiente de Determinaci√≥n (R¬≤)**: Un valor entre 0 y 1 que indica qu√© tan bien las variables independientes explican la variabilidad de la variable dependiente.

---

## üìö Librer√≠as y Requisitos

Para ejecutar este an√°lisis, aseg√∫rate de tener instalados los `requirements.txt`

```bash
pip install -r requirements.txt
```
