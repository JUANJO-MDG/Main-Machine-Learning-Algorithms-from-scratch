# üéì Implementaci√≥n de Naive Bayes para Clasificaci√≥n Categ√≥rica

Este proyecto es una implementaci√≥n **completa y did√°ctica** del algoritmo de clasificaci√≥n **Naive Bayes** desde cero, utilizando la librer√≠a `pandas` para la manipulaci√≥n de datos. A diferencia de las librer√≠as de alto nivel como `scikit-learn`, esta implementaci√≥n se centra en construir el modelo paso a paso para comprender a fondo sus principios matem√°ticos y la l√≥gica de la programaci√≥n.

El proyecto abarca la teor√≠a fundamental del Teorema de Bayes y su suposici√≥n de "ingenuidad", y luego la traduce directamente en c√≥digo funcional, incluyendo una t√©cnica esencial para la robustez del modelo: el **suavizado de Laplace**.

---

## üõ†Ô∏è Metodolog√≠a y Componentes del Modelo

El n√∫cleo del proyecto es la clase `NaiveBayesClassifier`, dise√±ada para ser **modular, intuitiva y robusta**.

### 1. Implementaci√≥n de la Clase `NaiveBayesClassifier`

La clase `NaiveBayesClassifier` se compone de m√©todos clave para el entrenamiento y la predicci√≥n:

- **Inicializaci√≥n (`__init__`)** Define los atributos principales del modelo:
  - `alpha`: El par√°metro de suavizado de Laplace, que evita probabilidades de cero.
  - `priors`: Un diccionario para almacenar las probabilidades a priori de cada clase.
  - `conditionals`: Un diccionario anidado para almacenar las probabilidades condicionales de cada caracter√≠stica.

---

### 2. Fases del Entrenamiento (`fit`)

El m√©todo `fit` es responsable de entrenar el modelo. Para ello, llama a dos funciones internas que calculan las probabilidades del dataset de entrenamiento:

- **C√°lculo de Probabilidades a Priori (`_calculate_priors`)** Calcula la probabilidad base de cada clase, es decir, la frecuencia de cada clase en el conjunto de datos de entrenamiento.

- **C√°lculo de Probabilidades Condicionales (`_calculate_conditionals`)** Calcula la probabilidad de que cada valor de caracter√≠stica ocurra, dado cada una de las clases. Aqu√≠ es donde se aplica la suposici√≥n de independencia de Naive Bayes. Adem√°s, se implementa el **suavizado de Laplace** para manejar valores no vistos, lo que asegura que ninguna probabilidad sea exactamente cero y evita errores de predicci√≥n.

---

### 3. Predicci√≥n (`predict`)

El m√©todo `predict` utiliza las probabilidades aprendidas para clasificar una nueva instancia:

1.  **Multiplicaci√≥n de Probabilidades:** Para cada clase, el m√©todo multiplica la probabilidad a priori de la clase por las probabilidades condicionales de todas las caracter√≠sticas de la nueva instancia.
2.  **Selecci√≥n de la Clase:** La clase con la probabilidad resultante m√°s alta es seleccionada como la predicci√≥n final.

---

## üìä Resultados y Evaluaci√≥n del Modelo

- El clasificador aprende las relaciones entre las caracter√≠sticas categ√≥ricas y la clase de manera eficiente.
- El uso de `pandas` facilita el preprocesamiento de datos y el c√°lculo de las probabilidades.
- El suavizado de Laplace asegura que el modelo pueda hacer predicciones correctas incluso si la nueva instancia contiene un valor que no se vio durante el entrenamiento.

Ejemplo de resultado:

- **Nueva Instancia**: `{'outlook': 'overcast', 'temp': 'hot', 'humidity': 'normal'}`
- **Probabilidad Posterior**: `{'yes': 0.0426, 'no': 0.0047}`
- **Clase Predicha**: `yes`

---

## üöÄ Conclusi√≥n

Este proyecto demuestra que es posible implementar un algoritmo de machine learning robusto como Naive Bayes con conocimientos fundamentales de programaci√≥n y estad√≠stica. Comprender los componentes internos de este modelo es crucial para cualquier cient√≠fico de datos o ingeniero de machine learning, ya que ofrece una visi√≥n clara de c√≥mo los datos se transforman en conocimiento predictivo.

---

## üõ†Ô∏è Requisitos de Instalaci√≥n

Para ejecutar este proyecto, instala los `requirements.txt`:

```bash
pip install -r requirements.txt
```
