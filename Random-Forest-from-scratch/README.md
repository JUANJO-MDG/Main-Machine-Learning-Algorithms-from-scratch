# üå≤ Implementaci√≥n Desde Cero de un Bosque Aleatorio para el Diagn√≥stico de C√°ncer de Mama

Este proyecto es una implementaci√≥n completa y did√°ctica de un modelo de **Bosque Aleatorio** (Random Forest) construido √≠ntegramente desde cero. A diferencia de las soluciones que utilizan librer√≠as de alto nivel como `scikit-learn` para el algoritmo principal, este proyecto se enfoca en la creaci√≥n de los componentes fundamentales, incluyendo la clase de **√Årbol de Decisi√≥n**, para ofrecer una comprensi√≥n profunda del funcionamiento interno del algoritmo.

El proyecto abarca todas las etapas del ciclo de vida del aprendizaje autom√°tico: desde el preprocesamiento de los datos y la construcci√≥n de las clases `DecisionTreeClassifier` y `RandomForest`, hasta la evaluaci√≥n exhaustiva del rendimiento del modelo.

---

## üõ†Ô∏è Metodolog√≠a y Componentes del Modelo

El n√∫cleo de este proyecto reside en la implementaci√≥n de dos clases principales: `DecisionTreeClassifier` y `RandomForest`.

### 1. Implementaci√≥n de la Clase `DecisionTreeClassifier` (Desde Cero)

La clase `DecisionTreeClassifier` fue construida de forma modular, replicando el proceso matem√°tico y l√≥gico de un √°rbol de decisi√≥n. Los pasos clave incluyen:

- **C√°lculo de la Entrop√≠a (`_calculate_entropy`)**: Se implement√≥ una funci√≥n para calcular la entrop√≠a, que es la medida de la incertidumbre o el desorden de las etiquetas de un conjunto de datos.
- **Ganancia de Informaci√≥n (`_information_gain`)**: Se cre√≥ una funci√≥n para calcular la ganancia de informaci√≥n, una m√©trica utilizada para determinar el mejor atributo para dividir los datos en cada paso del crecimiento del √°rbol.
- **B√∫squeda de la Mejor Divisi√≥n (`_best_split`)**: El algoritmo recorre todas las caracter√≠sticas y umbrales para encontrar la divisi√≥n que maximiza la ganancia de informaci√≥n.
- **Crecimiento Recursivo del √Årbol (`_grow_tree`)**: El √°rbol se construye de manera recursiva, creando nodos hijos hasta que se cumplen las condiciones de parada, como alcanzar la profundidad m√°xima o un n√∫mero m√≠nimo de muestras.

### 2. Implementaci√≥n de la Clase `RandomForest` (Desde Cero)

La clase `RandomForest` fue dise√±ada para orquestar m√∫ltiples instancias de la clase `DecisionTreeClassifier` implementada de forma personalizada. Su funcionamiento se basa en dos conceptos clave:

- **Bootstrapping**: El m√©todo `_bootstrap_samples` crea subconjuntos de datos aleatorios con reemplazo para entrenar cada uno de los √°rboles del bosque, asegurando que cada √°rbol vea un conjunto de datos ligeramente diferente.
- **Predicci√≥n por Votaci√≥n**: El m√©todo `predict` recopila las predicciones de cada √°rbol individual y utiliza una votaci√≥n por mayor√≠a (`_most_common`) para determinar la predicci√≥n final del modelo.

---

## üìä Resultados y Evaluaci√≥n del Modelo

El modelo se entren√≥ con 50 √°rboles (`n_trees=50`), una profundidad m√°xima de 10 (`max_depth=10`) y un m√≠nimo de 2 muestras para la divisi√≥n (`min_samples_split=2`). La evaluaci√≥n en el conjunto de prueba arroj√≥ las siguientes m√©tricas, demostrando un rendimiento excepcional en la clasificaci√≥n:

- **Accuracy (Precisi√≥n): 97.90%**: El modelo acert√≥ en la predicci√≥n del diagn√≥stico el 97.90% de las veces.
- **Precision (Precisi√≥n): 97.67%**: De todos los casos que el modelo predijo como positivos, el 97.67% eran realmente positivos.
- **F1 Score: 98.2456%**: Este valor demuestra un excelente equilibrio entre la precisi√≥n y el _recall_, lo que indica un rendimiento robusto del modelo.

### Matriz de Confusi√≥n

La matriz de confusi√≥n proporciona una visi√≥n detallada de los resultados del modelo:

```
[[56  2]
[ 1 84]]
```

- **Verdaderos Negativos (TN = 56)**: El modelo predijo correctamente que 56 pacientes no ten√≠an c√°ncer.
- **Falsos Positivos (FP = 2)**: El modelo predijo incorrectamente que 2 pacientes ten√≠an c√°ncer (errores de Tipo I).
- **Falsos Negativos (FN = 1)**: El modelo predijo incorrectamente que 1 paciente no ten√≠a c√°ncer (error de Tipo II), lo que demuestra la alta sensibilidad del modelo.
- **Verdaderos Positivos (TP = 84)**: El modelo predijo correctamente que 84 pacientes s√≠ ten√≠an c√°ncer.

---

## üöÄ Conclusi√≥n

El modelo de Bosque Aleatorio desarrollado desde cero demostr√≥ ser altamente efectivo para el diagn√≥stico de c√°ncer de mama. La alta precisi√≥n y el bajo n√∫mero de falsos negativos son particularmente notables, destacando la robustez y confiabilidad del modelo para una tarea tan cr√≠tica. Este proyecto sirve como una excelente base para entender c√≥mo funcionan los algoritmos de ensamblaje y c√≥mo se implementan sus componentes desde sus principios matem√°ticos.

---

## üõ†Ô∏è Requisitos de Instalaci√≥n

Para ejecutar este proyecto, necesitar√°s instalar los `requirements.txt`:

```bash
pip install -r requirements.txt
```

Nota: scikit-learn se utiliza √∫nicamente para las funciones de evaluaci√≥n (m√©tricas), no para la implementaci√≥n del algoritmo central, que se construy√≥ de forma manual.
