# üöÄ Modelo de Regresi√≥n Log√≠stica Desde Cero para el Diagn√≥stico de C√°ncer de Mama

Este proyecto es una implementaci√≥n completa y did√°ctica de un modelo de **Regresi√≥n Log√≠stica** construido desde cero, sin el uso de librer√≠as de Machine Learning de alto nivel como scikit-learn para el algoritmo central. El objetivo es proporcionar un entendimiento profundo de c√≥mo funciona este algoritmo de clasificaci√≥n, aplic√°ndolo al problema crucial del diagn√≥stico de c√°ncer de mama.

El proyecto abarca todas las etapas del ciclo de vida del aprendizaje autom√°tico: desde el an√°lisis exploratorio de datos y el preprocesamiento, hasta el entrenamiento, la visualizaci√≥n de la convergencia y la evaluaci√≥n exhaustiva del rendimiento del modelo.

---

## üî¨ An√°lisis Exploratorio de Datos (EDA)

Antes de construir el modelo, se realiz√≥ un an√°lisis exploratorio de datos para comprender mejor las variables y su relaci√≥n. Los pasos clave incluyeron:

1.  **Carga y Vista Previa**: Se carg√≥ el archivo `Breast_cancer_data.csv` en un DataFrame de pandas y se inspeccionaron las primeras filas para verificar la estructura.
2.  **An√°lisis de Correlaci√≥n**: Se gener√≥ un mapa de calor (`heatmap`) para visualizar la matriz de correlaci√≥n entre todas las variables. Esto permiti√≥ identificar las caracter√≠sticas con una alta correlaci√≥n con la variable objetivo (`diagnosis`).
3.  **Visualizaci√≥n de la Distribuci√≥n**: Se crearon gr√°ficos de caja (`boxplots`) para cada caracter√≠stica con el fin de examinar la distribuci√≥n de los datos, identificar la presencia de valores at√≠picos (outliers) y entender la variabilidad de cada variable.

---

## üõ†Ô∏è Metodolog√≠a y Componentes del Modelo

### 1. Preprocesamiento y Preparaci√≥n de Datos

Se realiz√≥ un preprocesamiento riguroso para asegurar la calidad y la robustez del modelo. Los pasos clave fueron:

- **Definici√≥n de Variables**: Se seleccionaron las siguientes caracter√≠sticas (`X`) como variables predictoras: `mean_radius`, `mean_texture`, `mean_perimeter`, `mean_area` y `mean_smoothness`. La variable objetivo (`y`) fue `diagnosis` (donde `0` = benigno, `1` = maligno).
- **Divisi√≥n de Datos**: Los datos se dividieron en un conjunto de entrenamiento (70%) y uno de prueba (30%) utilizando `train_test_split`. Una semilla aleatoria (`random_state=42`) se fij√≥ para garantizar la reproducibilidad de la divisi√≥n.
- **Estandarizaci√≥n de Caracter√≠sticas**: Se aplic√≥ `StandardScaler` para estandarizar las caracter√≠sticas de entrada. Este paso es fundamental para los modelos basados en descenso de gradiente, ya que las variables con diferentes escalas pueden afectar la convergencia del algoritmo.

### 2. Implementaci√≥n de la Clase `LogisticRegression`

La clase **`LogisticRegression`** fue construida de forma modular, implementando cada componente matem√°tico necesario para el algoritmo.

- **Constructor (`__init__`)**: Inicializa la tasa de aprendizaje (`lr`), el n√∫mero de √©pocas (`epochs`), los pesos (`weights`), el sesgo (`bias`) y la historia del costo (`cost_history`).
- **Funci√≥n Sigmoide (`_sigmoid`)**: Esta funci√≥n de activaci√≥n es el coraz√≥n de la regresi√≥n log√≠stica. Convierte la salida lineal en una probabilidad entre 0 y 1.
- **Funci√≥n de P√©rdida (`_loss_function`)**: Se implement√≥ la **entrop√≠a cruzada binaria**, que es la funci√≥n de p√©rdida est√°ndar para problemas de clasificaci√≥n. Su objetivo es penalizar al modelo por predicciones incorrectas, guiando el proceso de optimizaci√≥n.
- **M√©todo de Entrenamiento (`fit`)**: Utiliza el algoritmo de **descenso de gradiente** para minimizar la funci√≥n de p√©rdida. En cada √©poca, calcula las predicciones, los gradientes y actualiza los pesos y el sesgo. La historia del costo se almacena para su posterior visualizaci√≥n.
- **M√©todo de Predicci√≥n (`predict`)**: Realiza predicciones sobre nuevos datos, convirtiendo las probabilidades en clases binarias (0 o 1) utilizando un umbral de `0.5`.
- **Visualizaci√≥n (`plot_cost_history`)**: Muestra c√≥mo el costo del modelo disminuye con cada √©poca, un indicador clave de que el proceso de optimizaci√≥n est√° funcionando correctamente.
- **Evaluaci√≥n (`evaluate`)**: Calcula un conjunto completo de m√©tricas de rendimiento (`Accuracy`, `Precision`, `Recall`, `F1 Score`) y la matriz de confusi√≥n.

---

## üìä Resultados y Evaluaci√≥n del Modelo

El modelo se entren√≥ con una tasa de aprendizaje de `0.02` y `10000` √©pocas. La evaluaci√≥n en el conjunto de prueba arroj√≥ las siguientes m√©tricas, demostrando un rendimiento excepcional en la clasificaci√≥n:

- **Accuracy (Precisi√≥n): 95.32%**: El modelo acert√≥ en la predicci√≥n del diagn√≥stico el 95.32% de las veces.
- **Precision (Precisi√≥n): 97.17%**: De todos los casos que el modelo predijo como positivos, el 97.17% eran realmente positivos. Esto indica un bajo n√∫mero de **falsos positivos**.
- **Recall (Sensibilidad): 95.00%**: El modelo fue capaz de identificar el 95% de todos los casos positivos reales. Este es un resultado crucial en el contexto de diagn√≥stico m√©dico, ya que un alto recall minimiza los **falsos negativos**, que pueden ser errores de alta gravedad.
- **F1 Score: 96.00%**: Este valor demuestra un excelente equilibrio entre la precisi√≥n y el recall, lo que indica un rendimiento robusto del modelo.

### Matriz de Confusi√≥n

La matriz de confusi√≥n proporciona una visi√≥n detallada de los resultados del modelo:

```
[[60   3]
[  5 103]]
```

- **Verdaderos Negativos (TN = 60)**: El modelo predijo correctamente que 60 pacientes no ten√≠an c√°ncer.
- **Verdaderos Positivos (TP = 103)**: El modelo predijo correctamente que 103 pacientes s√≠ ten√≠an c√°ncer.
- **Falsos Positivos (FP = 3)**: El modelo predijo incorrectamente que 3 pacientes ten√≠an c√°ncer (errores de Tipo I).
- **Falsos Negativos (FN = 5)**: El modelo predijo incorrectamente que 5 pacientes no ten√≠an c√°ncer (errores de Tipo II).

---

## üöÄ Conclusi√≥n

El modelo de Regresi√≥n Log√≠stica desarrollado desde cero demostr√≥ ser muy efectivo para la tarea de diagn√≥stico de c√°ncer de mama, logrando un alto rendimiento en todas las m√©tricas. La alta sensibilidad (recall) es particularmente notable, ya que minimiza el riesgo de pasar por alto un diagn√≥stico positivo, un aspecto cr√≠tico en el sector de la salud.

Este proyecto sirve como una excelente base para entender c√≥mo funcionan los algoritmos de clasificaci√≥n de aprendizaje autom√°tico y c√≥mo se implementan sus componentes desde sus principios matem√°ticos.

---

## üõ†Ô∏è Requisitos de Instalaci√≥n

Para ejecutar este proyecto, necesitar√°s instalar los requirements.txt:

```bash
pip install -r requirements.txt
```
