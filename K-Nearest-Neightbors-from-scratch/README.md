# üöÄ Modelo K-Nearest Neighbors (KNN) Desde Cero para la Clasificaci√≥n de Flores Iris

Este proyecto es una implementaci√≥n completa y did√°ctica de un modelo de **K-Nearest Neighbors (KNN)** construido desde cero, utilizando √∫nicamente la biblioteca NumPy. El objetivo es proporcionar un entendimiento profundo de c√≥mo funciona este algoritmo de clasificaci√≥n, aplic√°ndolo al problema cl√°sico de la clasificaci√≥n de las especies de la flor Iris.

El proyecto abarca todas las etapas del ciclo de vida del aprendizaje autom√°tico: desde el an√°lisis exploratorio de datos (EDA) y el preprocesamiento, hasta la implementaci√≥n de un clasificador personalizado, el entrenamiento, la predicci√≥n y la evaluaci√≥n exhaustiva del rendimiento.

---

## üî¨ An√°lisis Exploratorio de Datos (EDA)

Antes de construir el modelo, se realiz√≥ un an√°lisis exploratorio de datos para comprender mejor las variables y su relaci√≥n. Los pasos clave incluyeron:

1.  **Carga y Vista Previa**: Se carg√≥ el archivo `IRIS.csv` en un DataFrame de pandas y se inspeccionaron las primeras filas para verificar la estructura.
2.  **An√°lisis de Correlaci√≥n**: Se gener√≥ un mapa de calor (`heatmap`) para visualizar la matriz de correlaci√≥n entre todas las variables. Esto permiti√≥ identificar las caracter√≠sticas con una alta correlaci√≥n con la variable objetivo (`species`).

---

## üõ†Ô∏è Metodolog√≠a y Componentes del Modelo

### 1. Preprocesamiento y Preparaci√≥n de Datos

Se realiz√≥ un preprocesamiento riguroso para asegurar la calidad y la robustez del modelo. Los pasos clave fueron:

* **Definici√≥n de Variables**: Se seleccionaron las siguientes caracter√≠sticas (`X`) como variables predictoras: `sepal_length`, `sepal_width`, `petal_length`, y `petal_width`. La variable objetivo (`y`) fue `species`.
* **Divisi√≥n de Datos**: Los datos se dividieron en un conjunto de entrenamiento (80%) y uno de prueba (20%) utilizando `train_test_split`.

### 2. Implementaci√≥n de la Clase `KNNeightborsClasifier`

La clase **`KNNeightborsClasifier`** fue construida de forma modular, implementando cada componente necesario para el algoritmo.

* **Constructor (`__init__`)**: Inicializa el n√∫mero de vecinos (`k`), la m√©trica de distancia y el tipo de tarea (`classification` o `regression`).
* **Funci√≥n de Distancia (`_distance`)**: Implementa el c√°lculo de distancias. Se incluyen la distancia **Eucl√≠dea** y la distancia de **Manhattan**, lo que permite una mayor flexibilidad en la experimentaci√≥n.
* **M√©todo de Entrenamiento (`fit`)**: Un m√©todo simple que almacena los datos de entrenamiento en la clase para su uso posterior en la fase de predicci√≥n.
* **M√©todo de Predicci√≥n (`predict`)**: Para cada punto de prueba, el m√©todo encuentra sus `k` vecinos m√°s cercanos en el conjunto de entrenamiento, determina la clase m√°s com√∫n entre ellos y asigna esa clase como la predicci√≥n final.
* **M√©todos de Evaluaci√≥n (`evaluate_classification`) o (`evaluate_regression`)**: Un m√©todo vers√°til que calcula y muestra m√©tricas de rendimiento tanto para **clasificaci√≥n** (Accuracy, Precision, Recall, F1-Score, Matriz de Confusi√≥n) como para **regresi√≥n** (MSE, MAE).
* **Visualizaci√≥n (`plot_predictions`)**: Un m√©todo para visualizar las predicciones del modelo en un gr√°fico de dispersi√≥n, lo que ayuda a entender el comportamiento del clasificador en un espacio de 2D.

---

## üìä Resultados y Evaluaci√≥n del Modelo

El modelo se entren√≥ con los datos de Iris, y la evaluaci√≥n en el conjunto de prueba arroj√≥ las siguientes m√©tricas, demostrando un rendimiento excelente:

* **Accuracy (Precisi√≥n)**: Un valor de precisi√≥n muy alto, indicando que el modelo clasific√≥ correctamente la gran mayor√≠a de las instancias.
* **Precision (Precisi√≥n)**: De todas las predicciones positivas, la mayor√≠a fueron correctas, lo que muestra un bajo n√∫mero de falsos positivos.
* **Recall (Sensibilidad)**: El modelo fue capaz de identificar la mayor√≠a de las instancias positivas, lo que minimiza los falsos negativos.
* **F1 Score**: Un valor alto que demuestra un buen equilibrio entre la precisi√≥n y el recall.

### Matriz de Confusi√≥n

La matriz de confusi√≥n proporciona una visi√≥n detallada de los resultados del modelo, mostrando la cantidad de predicciones correctas e incorrectas para cada clase, lo cual es fundamental para el an√°lisis de los errores del modelo.

---

## üöÄ Conclusi√≥n

El modelo KNN implementado desde cero demostr√≥ ser un clasificador robusto y efectivo para el conjunto de datos de Iris. Este proyecto no solo cumple su funci√≥n de clasificar las especies de flores, sino que tambi√©n sirve como una excelente herramienta de aprendizaje para comprender los fundamentos de uno de los algoritmos de aprendizaje autom√°tico m√°s intuitivos y populares.

---

## üõ†Ô∏è Requisitos de Instalaci√≥n

Para ejecutar este proyecto, necesitar√°s instalar los `requirements.txt`:

```bash
pip install -r requirements.txt